{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meghorikawa/ULLM/blob/main/ULLMs_Groq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_vx_WZa1L07",
        "outputId": "0e3fe48c-ce48-4aef-a74e-d668e6ea3ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n",
            "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, groq\n",
            "Successfully installed groq-0.11.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "import os\n",
        "from groq import Groq\n",
        "import json\n",
        "import time\n",
        "\n",
        "\n",
        "api_key = userdata.get('groq_api_key')\n",
        "%env GROQ_API_KEY=$api_key #input your own Groq API key here"
      ],
      "metadata": {
        "id": "Gnk1D9p6015R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c7cde2-e212-491b-f961-9da67c2d2413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: GROQ_API_KEY=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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in data\n",
        "df = pd.read_csv('/content/AnnotatedData.csv') # load in data from contents file\n",
        "google_sheet = \"/content/prompt_examples.csv\"\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LqhV-8ayqpzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split df into two dfs with messages belonging to the two different tasks: \"Comparing Athletes\" and \"Buying a Birthday Present\"\n",
        "mask = df['task'] == \"Comparing Athletes\"\n",
        "athletes_df = df[mask]\n",
        "bday_df = df[~mask]"
      ],
      "metadata": {
        "id": "iI6A_h3hsY9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IterDialog:\n",
        "  \"\"\"\n",
        "  An Iterator to go through all the messages in a dialog dataframe and\n",
        "  output the history of the corresponding dialog as a list of messages,\n",
        "  with the interaction in question as the last index\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, df):\n",
        "    \"\"\"\n",
        "    Initialize the iterator with the dataframe and the pointer as the index of\n",
        "    the first row\n",
        "    \"\"\"\n",
        "    self.df = df\n",
        "    self.pointer = None\n",
        "\n",
        "  def __next__(self):\n",
        "    \"\"\"\n",
        "    Gets the history of the next message in the dataframe and advances the pointer.\n",
        "    The message in question is the last item in the returned list.\n",
        "    \"\"\"\n",
        "\n",
        "    if self.pointer == None:\n",
        "      self.pointer = df.index[0]\n",
        "    else:\n",
        "      self.pointer += 1\n",
        "\n",
        "    history = []\n",
        "    row = self.df.loc[self.pointer]\n",
        "    cur_id = row['dialog_id']\n",
        "    # a smaller df containing only the current conversation\n",
        "    cur_dialog_df = self.df[(self.df['dialog_id'] == cur_id)]\n",
        "\n",
        "    # if there are rows with a lower index and the same dialog_id, those messages came first. Add those to the history.\n",
        "    for _, prev_row in cur_dialog_df[cur_dialog_df.index < self.pointer].iterrows():\n",
        "        history.append(f\"BOT: {prev_row['bot_elicitation']}\")\n",
        "        history.append(f\"STUDENT: {prev_row['user_input']}\")\n",
        "\n",
        "    # add bot_elicitation and user input at current point\n",
        "    history.append(f\"BOT: {row['bot_elicitation']}\")\n",
        "    history.append(f\"STUDENT: {row['user_input']}\")\n",
        "\n",
        "\n",
        "    return history\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.df)\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self\n",
        "\n",
        "  def get_target_constr(self):\n",
        "    \"\"\"\n",
        "    For getting the target construct associated ith this turn in conversation.\n",
        "    Returns None when there is no target construct being elicted\n",
        "    \"\"\"\n",
        "    target_constr = self.df.loc[self.pointer][\"target_constr\"]\n",
        "    return None if (pd.isna(target_constr) or target_constr == None) else target_constr\n",
        "\n",
        "  def has_next(self):\n",
        "    \"\"\"\n",
        "    Whether the iterator has a next message\n",
        "    \"\"\"\n",
        "    return self.pointer != self.df.index[-1]\n",
        "\n",
        "  def restart(self):\n",
        "    \"\"\"\n",
        "    Moves pointer to beginning\n",
        "    \"\"\"\n",
        "    self.pointer = None\n",
        "\n"
      ],
      "metadata": {
        "id": "FnClry_y6x6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def example_maker(task,  prompt_type, num):\n",
        "  \"\"\"\n",
        "  Method to compile examples based on the task and type of prompting\n",
        "  ______________\n",
        "\n",
        "  Parameters:\n",
        "    task: either 'Birthday Present' or 'Comparing Athletes'\n",
        "    prompt_type: COT for Chain of Thought or FS for few-shot without CoT.\n",
        "    num: number of examples\n",
        "  returns a string of the formatted examples to be included in the prompt.\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(google_sheet)\n",
        "  df = df[df['Task'] == task].reset_index(drop=True)\n",
        "  prompt_examples = ''\n",
        "  i = 0\n",
        "\n",
        "  for i in range(min(num, len(df))):\n",
        "\n",
        "    # Fill in the COT JSON example output first.\n",
        "    json_cot = {}\n",
        "    json_fs = {}\n",
        "\n",
        "    context = df.loc[i, 'dialogue_context']\n",
        "    response = df.loc[i, 'student_input']\n",
        "\n",
        "    json_cot[\"relevance_thought\"] = df.loc[i, \"relevance_cot\"]\n",
        "    json_cot[\"relevance\"] = str(df.loc[i, 'relevant']) # Needs to be cast as string to use json.dumps\n",
        "\n",
        "    json_cot[\"construct_thought\"] = \"None\" if pd.isna(df.loc[i, \"target_construct_cot\"]) else df.loc[i, \"target_construct_cot\"]\n",
        "    json_cot[\"construct\"] = \"None\" if pd.isna(df.loc[i, 'target_construct']) else df.loc[i, 'target_construct']\n",
        "\n",
        "    # \"Birthday Present\" requires no factuality check\n",
        "    if task == \"Comparing Athletes\":\n",
        "      json_cot[\"factual_thought\"] = df.loc[i, \"factual_cot\"]\n",
        "      json_cot[\"factual\"] = str(df.loc[i, \"factual\"])\n",
        "\n",
        "    # Fill in the few-shot JSON by removing the keys with chains of thought\n",
        "    for key, value in json_cot.items():\n",
        "      if \"thought\" not in key:\n",
        "        json_fs[key] = str(value)\n",
        "\n",
        "    if prompt_type == \"FS\":\n",
        "      json_example = json_fs\n",
        "    else:\n",
        "      json_example = json_cot\n",
        "\n",
        "    # Get a string from the JSON example\n",
        "    json_example = json.dumps(json_example)\n",
        "\n",
        "    string = f\"\\nGiven the following CONTEXT:\\n\\n{context}\\n{response}\\n\\n The OUTPUT should be: \\n{json_example}\\n\\n\"\n",
        "\n",
        "    prompt_examples += string\n",
        "    i += 1\n",
        "\n",
        "  return prompt_examples"
      ],
      "metadata": {
        "id": "ZWVyuZY93fqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Task instructions\n",
        "\n",
        "#\"Birthday Gift\"\n",
        "bg_task_instructions = '''Task Instructions: Your friend Max is having a birthday soon! Let's go shopping to buy him a present. Ask the shop assistant to help you find a gift he will like.\n",
        "Remember that Max likes video games, music, and movies.\n",
        "Here is some language that may help you:\n",
        "You can use the present progressive form when you are searching for something\n",
        "I am looking for a birthday gift for my friend.\n",
        "I am searching for a birthday present for my friend.\n",
        "You can use a comparative adjective to ask for more options\n",
        "Do you have something cheaper?'''\n",
        "\n",
        "#\"Comparing athletes\"\n",
        "ca_task_instructions = '''\n",
        "You and Max are discussing the results of the school Decathlon, a competition with 10 events. You watched Day 1, but Max missed it. Explain what happened on Day 1.\n",
        "Here is some language that may help you:\n",
        "Peter did better than Andy in the Day 1 events.\n",
        "Peter ran faster than Andy in the 100 meters.\n",
        "\n",
        "{\"events\": [\n",
        "    {\n",
        "      \"event\": \"100 metres\",\n",
        "      \"peter\": \"13 seconds\",\n",
        "      \"andy\": \"13.5 seconds\",\n",
        "    },\n",
        "    {\n",
        "      \"event\": \"Long jump\",\n",
        "      \"peter\": \"168 cm\",\n",
        "      \"andy\": \"170 cm\"\n",
        "    },\n",
        "    {\n",
        "      \"event\": \"Shot put\",\n",
        "      \"peter\": \"9.1 m\",\n",
        "      \"andy\": \"8.9 m\"\n",
        "    },\n",
        "    {\n",
        "      \"event\": \"High jump\",\n",
        "      \"peter\": \"130 m\",\n",
        "      \"andy\": \"150 m\"\n",
        "    },\n",
        "    {\n",
        "      \"event\": \"400 metres\",\n",
        "      \"peter\": \"85 seconds\",\n",
        "      \"andy\": \"100 seconds\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "'''"
      ],
      "metadata": {
        "id": "9OXvOkCk3U94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JSON Formats for the prompt.\n",
        "COT_JSON = '''{\n",
        "  \"relevance_thought\": <Step-by-step reasoning for whether the student's answer was relevant to the question being asked>,\n",
        "  \"relevance\": <Boolean for whether the answer is relevant or not>,\n",
        "  \"factual_thought\": <Step-by-step reasoning for whether the student's last answer is factual, comparing the information given in the task instructions and the one privided by the student.>,\n",
        "  \"factual\": <Boolean for whether the answer is factual or not>,\n",
        "  \"construct_thought\": <Step-by-step reasoning for whether the student's last answer contains the specified target construct>,\n",
        "  \"construct_present\": <Boolean for whether the answer contains the target construct or not, or \"None\" if the target construct is None>\n",
        "\n",
        "  \"\"\n",
        "}'''\n",
        "\n",
        "FS_JSON = '''{\n",
        "  \"relevance\": Boolean,\n",
        "  \"factual\": Boolean,\n",
        "  \"construct_present\": True/False or None if the target construct is None\n",
        "}'''\n",
        "\n",
        "def prompt_builder(examples, task, context, student_input, target_construct, prompt_type):\n",
        "\n",
        "  \"\"\"\n",
        "  Prompt-builder method\n",
        "  parameters:\n",
        "  Examples : the examples to be included in the prompt\n",
        "  task: the name of the task\n",
        "  dialogue_context: The previous dialogue context to be included in the prompt\n",
        "  student_input: the student input to be included in the prompt\n",
        "  target_construct: the target construct to be included in the prompt\n",
        "  p_type: the type of prompting, either COT or FS\n",
        "  returns: the prompt to be sent to the LLM\n",
        "  \"\"\"\n",
        "  if prompt_type == 'COT':\n",
        "    JSON = COT_JSON\n",
        "  if prompt_type == 'FS':\n",
        "    JSON = FS_JSON\n",
        "\n",
        "\n",
        "  factual_prompt = \"\"\n",
        "  if task == \"Birthday Present\":\n",
        "    instructions = bg_task_instructions\n",
        "  else:\n",
        "    instructions = ca_task_instructions\n",
        "    # only \"Comparing Athletes\" requires JSON with factuality information. Add this to the prompt if it's this task\n",
        "    factual_prompt = \"Finally, also inlcude information about whether the student's input is factually correct based on the task instructions.\"\n",
        "\n",
        "\n",
        "  prompt = f'''\n",
        "[INST]\n",
        "You are a helpful teaching assistant for English as a second language.\n",
        "ESL students are talking to a chatbot that works with string-matching to complete a task.\n",
        "The chatbot does not always recognize when a user's answer is valid. When it does not, it asks the question again or tries to elicit an answer in a different way.\n",
        "\n",
        "\n",
        "Based on the conversation history and the instructions of the chatbot task, your job is to output a JSON object, stating whether the last student response is relevant.\n",
        "Importantly, we define \"relevant\" as providing a plausible answer to the question with all necessary information and which will not interrupt the flow of the conversation.\n",
        "The JSON object should also state whether the message at hand contains a given grammatical construct. If the target construct is \"None\", the value of this property should be the string \"None\".\n",
        "One property in a JSON object must never have more than one value.  The JSON must be valid, so all strings MUST be surrounded by double quotes (\") and not by single quotes. Double quotes in strings should be escaped.\n",
        "{factual_prompt}\n",
        "\n",
        "Ignore typos and grammar issues. Answer based on what you understand the student's answer to be meant to represent.\n",
        "\n",
        "The JSON object should follow this schema:\n",
        "\n",
        "{JSON}\n",
        "______\n",
        "Here are some examples for how to do this:\n",
        "\n",
        "{examples}\n",
        "______\n",
        "\n",
        "Now it is your turn. Here is all the information you need.\n",
        "______\n",
        "TASK INSTRUCTIONS:\n",
        "{instructions}\n",
        "______\n",
        "CONVERSATION HISTORY:\n",
        "{context}\n",
        "______\n",
        "STUDENT RESPONSE:\n",
        "{student_input}\n",
        "______\n",
        "CONSTRUCT:\n",
        "{str(target_construct)}\n",
        "\n",
        "[/INST]\n",
        "  '''\n",
        "\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "iIjxhtQAkEKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Groq client with API key (obtained from Groq playground: )\n",
        "client = Groq(\n",
        "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        ")"
      ],
      "metadata": {
        "id": "gH-_JGxx1Sdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt):\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"mixtral-8x7b-32768\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "        }\n",
        "    ],\n",
        "    temperature=0,\n",
        "    top_p=1,\n",
        "    stream=False,\n",
        "    response_format={\"type\": \"json_object\"},\n",
        "    stop=None,\n",
        "  )\n",
        "\n",
        "  return completion.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "F1IUIKqk1WMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "athletes_iter = IterDialog(athletes_df)\n",
        "bday_iter = IterDialog(bday_df)\n",
        "\n",
        "prompt_type = \"FS\" # NOTE: change to COT once FS is done\n",
        "# Loop over tasks and number of examples\n",
        "for iterator in [bday_iter, athletes_iter]:\n",
        "  if iterator == athletes_iter:\n",
        "    task = \"Comparing Athletes\"\n",
        "    df = athletes_df\n",
        "  else:\n",
        "    task = \"Birthday Present\"\n",
        "    df = bday_df\n",
        "\n",
        "  # iterate throgh different numbers for the k-shot examples\n",
        "  for k in range(0, 6):\n",
        "    examples = example_maker(task, prompt_type, k)\n",
        "\n",
        "    while iterator.has_next():\n",
        "      # save completion in dataframe\n",
        "      condition = task.replace(\" \", \"\") + \"_\" + prompt_type + \"_\" + str(k) # prompttype_k value (e.g. Birthday_Present_FS_3)\n",
        "\n",
        "      # if it's the first time this condition is used, add the corresponding column to the dataframe\n",
        "      if condition not in df:\n",
        "        print(condition)\n",
        "        df[condition] = \"\"\n",
        "\n",
        "      history = next(iterator)\n",
        "\n",
        "      context = history[:-1]\n",
        "      student_input = history[-1]\n",
        "      target_constr = iterator.get_target_constr()\n",
        "      prompt = prompt_builder(examples, task, context, student_input, target_constr, prompt_type)\n",
        "\n",
        "      if df.loc[iterator.pointer, condition] == \"\" or pd.isna(df.loc[iterator.pointer, condition]): # Only get completion if it has not been done before\n",
        "        start = time.time()\n",
        "        print(iterator.pointer)\n",
        "        completion = get_completion(prompt)\n",
        "\n",
        "        df.loc[iterator.pointer, condition] = completion\n",
        "\n",
        "        time.sleep(0.25) # limit the number of requests per minute to prevent issues with rate limits\n",
        "        end = time.time()\n",
        "        print(\"The completion took \" + str(end - start))\n",
        "    iterator.restart()"
      ],
      "metadata": {
        "id": "OuTlEKxmtEz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a32cf8b0-74db-4079-f3d9-53aa5f391fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n",
            "The completion took 0.7326431274414062\n",
            "25\n",
            "The completion took 0.7105712890625\n",
            "26\n",
            "The completion took 0.6947355270385742\n",
            "27\n",
            "The completion took 0.9924561977386475\n",
            "28\n",
            "The completion took 13.791840076446533\n",
            "29\n",
            "The completion took 15.92470669746399\n",
            "30\n",
            "The completion took 18.91845726966858\n",
            "31\n",
            "The completion took 18.870135068893433\n",
            "32\n",
            "The completion took 13.789597034454346\n",
            "33\n",
            "The completion took 12.812562465667725\n",
            "34\n",
            "The completion took 13.843945980072021\n",
            "35\n",
            "The completion took 13.838682651519775\n",
            "36\n",
            "The completion took 14.918617010116577\n",
            "37\n",
            "The completion took 15.877822399139404\n",
            "38\n",
            "The completion took 16.097659587860107\n",
            "39\n",
            "The completion took 15.820312976837158\n",
            "40\n",
            "The completion took 16.426499366760254\n",
            "41\n",
            "The completion took 14.952352523803711\n",
            "42\n",
            "The completion took 16.78404927253723\n",
            "43\n",
            "The completion took 16.91515588760376\n",
            "44\n",
            "The completion took 17.840951204299927\n",
            "45\n",
            "The completion took 13.797117233276367\n",
            "46\n",
            "The completion took 14.162178993225098\n",
            "47\n",
            "The completion took 13.926829099655151\n",
            "48\n",
            "The completion took 14.937054634094238\n",
            "49\n",
            "The completion took 14.989051103591919\n",
            "50\n",
            "The completion took 16.989557027816772\n",
            "51\n",
            "The completion took 15.929628372192383\n",
            "52\n",
            "The completion took 17.894461393356323\n",
            "53\n",
            "The completion took 17.42392349243164\n",
            "54\n",
            "The completion took 13.98177194595337\n",
            "55\n",
            "The completion took 13.800657749176025\n",
            "56\n",
            "The completion took 13.897974014282227\n",
            "57\n",
            "The completion took 14.083721399307251\n",
            "58\n",
            "The completion took 14.775296449661255\n",
            "59\n",
            "The completion took 14.955406904220581\n",
            "60\n",
            "The completion took 15.821054935455322\n",
            "61\n",
            "The completion took 16.587067127227783\n",
            "62\n",
            "The completion took 15.890244245529175\n",
            "63\n",
            "The completion took 16.789327383041382\n",
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save dataframes to CSV\n",
        "bday_df.to_csv(\"bday_df.csv\", sep=',', encoding='utf-8')"
      ],
      "metadata": {
        "id": "n7Zay7iwBPWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save dataframe to CSV\n",
        "athletes_df.to_csv(\"athletes_df.csv\", sep=',', encoding='utf-8')"
      ],
      "metadata": {
        "id": "KYYYfCLRpTxs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}